<tool id="ludwig_experiment" name="Ludwig Experiment" version="@VERSION@" profile="@PROFILE@">
    <description>trains and evaluates a model</description>
    <macros>
        <import>ludwig_macros.xml</import>
    </macros>
    <expand macro="python_requirements" />
    <expand macro="macro_stdio" />
    <version_command>echo "@VERSION@"</version_command>
    <command>
        <![CDATA[
            #if $config
            ln -sf '$config' "`pwd`/config.yml";
            #end if
            #if $dataset
            ln -sf '$dataset' "`pwd`/${dataset.element_identifier}";
            #end if
            #if $training_set
            ln -sf '$training_set' "`pwd`/${training_set.element_identifier}";
            #end if
            #if $validation_set
            ln -sf '$validation_set' "`pwd`/${validation_set.element_identifier}";
            #end if
            #if $test_set
            ln -sf '$test_set' "`pwd`/${test_set.element_identifier}";
            #end if
            #if $raw_data
            unzip -o -q '$raw_data' -d ./;
            #end if
            python '$__tool_directory__/ludwig_experiment.py'
                #if $config
                --config "`pwd`/config.yml"
                #end if
                #if $model_load_path
                --model_load_path '$model_load_path.extra_files_path'
                #end if
                #if $model_resume_path
                --model_resume_path '$model_resume_path.model_resume_path'
                #end if
                #if $dataset
                --dataset "`pwd`/${dataset.element_identifier}"
                #end if
                #if $training_set
                --training_set "`pwd`/${training_set.element_identifier}"
                #end if
                #if $validation_set
                --validation_set "`pwd`/${validation_set.element_identifier}"
                #end if
                #if $test_set
                --test_set "`pwd`/${test_set.element_identifier}"
                #end if
                #if $training_set_metadata
                --training_set_metadata '$training_set_metadata'
                #end if
                #if $disable_parallel_threads
                --disable_parallel_threads
                #end if
                #if $k_fold
                --k_fold '$k_fold'
                #end if
                --output_directory "`pwd`"
                --data_format '$data_format'
                --backend local
                --eval_split '$eval_split'
                --random_seed $random_seed
                --skip_save_unprocessed_output
                #if $skip_save_predictions
                --skip_save_predictions
                #end if
                --skip_save_k_fold_split_indices &&
            cd experiment_run &&
            mkdir -p '$output_model.extra_files_path' &&
            cp -r model/* '$output_model.extra_files_path' &&
            #if not $skip_save_predictions
            cp '$__tool_directory__/ludwig_predict_result.html' '$output_pred' &&
            mkdir -p '$output_pred.extra_files_path' &&
            mv predictions.parquet predictions.shapes.json '$output_pred.extra_files_path' &&
            #end if
            cp '$__tool_directory__/ludwig_experiment_result.html' '$output_stat' &&
            mkdir -p '$output_stat.extra_files_path' &&
            cp *.json '$output_stat.extra_files_path' &&

            echo "Experiment is Done!"
        ]]>
    </command>
    <configfiles>
        <inputs name="inputs" />
    </configfiles>
    <inputs>
        <param argument="config" type="data" format="yaml" label="Select the dataset containing model configuration" />
        <param argument="model_load_path" type="data" format="ludwig_model" optional="true" label="Load a pretrained model as initialization" help="Optional." />
        <param argument="model_resume_path" type="data" format="ludwig_model" optional="true" label="Load a pretained model to resume training" help="Optional." />
        <param argument="dataset" type="data" format="tabular,csv,h5,json,txt" optional="true" label="Input dataset" />
        <param argument="training_set" type="data" format="tabular,csv,h5,json" optional="true" label="Input traning dataset" />
        <param argument="validation_set" type="data" format="tabular,csv,h5,json" optional="true" label="Input validation dataset" />
        <param argument="test_set" type="data" format="tabular,csv,h5,json" optional="true" label="Input test dataset" />
        <param argument="training_set_metadata" type="data" format="json" optional="true" label="Training set metadata" />
        <param argument="data_format" type="select" label="Data format">
            <option value="auto" selected="true">auto</option>
            <option value="tsv">tsv</option>
            <option value="csv">csv</option>
            <option value="h5">h5</option>
            <option value="json">json</option>
        </param>
        <param argument="eval_split" type="select" label="Select the split portion for evaluation">
            <option value="training">training</option>
            <option value="validation">validation</option>
            <option value="test" selected="true">test</option>
            <option value="full">full</option>
        </param>
        <param argument="k_fold" type="integer" value="" optional="true" label="number of folds for a k-fold cross validation run" />
        <param argument="random_seed" type="integer" value="42" label="Randonness seed" />
        <param argument="disable_parallel_threads" type="boolean" checked="false" label="Whether to disable parallel threads for reproducibility?" />
        <param argument="skip_save_predictions" type="boolean" checked="false" label="Whether to skip saving predictions?" />
        <param name="raw_data" type="data" format="zip" optional="true" label="Raw data" help="Optional. Needed for images."/>
    </inputs>       
    <outputs>
        <data format="ludwig_model" name="output_model" label="${tool.name} trained model on ${on_string}" />
        <data format="html" name="output_stat" label="${tool.name} description and statistics on ${on_string}" />
        <data format="html" name="output_pred" label="${tool.name} predictions parquet on ${on_string}" >
            <filter>not skip_save_predictions</filter>
        </data>
        <collection type="list" name="output_pred_csv" label="${tool.name} predictions CSV on ${on_string}" >
            <discover_datasets pattern="(?P&lt;designation&gt;.+)\.csv" format="csv" directory="experiment_run" />
            <filter>not skip_save_predictions</filter>
        </collection>
    </outputs>
    <tests>
        <test>
            <param name="dataset" value="temperature_la.csv" ftype="csv" />
            <param name="config" value="temperature_config.yml" ftype="yaml" />
            <param name="data_format" value="csv" />
            <output name="output_stat" file="temperature_experiment.html" compare="sim_size" delta="10" />
        </test>
    </tests>
    <help>
        <![CDATA[
**What it does**
Ludwig Experiment: train on one (portion of) dataset and evalue the model performance on another (portion of) dataset.


**Output**
An HTML containing the evaluation report of the trained model.
A trained Ludwig model composite dataset.
(Optional) Predictions results from the model evaluations.


        ]]>
    </help>
    <citations>
        <citation type="bibtex">
        </citation>
    </citations>
</tool>
